{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a1d61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports and environment setup\n",
    "import os  # standard library: read environment variables for keys in a secure, cross-platform way\n",
    "from google import genai  # official Google Gen AI SDK entrypoint [1]\n",
    "from google.genai import types  # typed request/response helpers, useful later for structured output [3]\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"\"\n",
    "# Read the API key from environment for safety (never hardcode secrets in notebooks or repos).\n",
    "# The SDK auto-detects GEMINI_API_KEY or GOOGLE_API_KEY; GOOGLE_API_KEY takes precedence if both exist [4].\n",
    "api_key = os.environ.get(\"GOOGLE_API_KEY\") or os.environ.get(\"GEMINI_API_KEY\")\n",
    "\n",
    "# Fail fast with a clear message if no key is present, and point the user at the official place to create one.\n",
    "if not api_key:\n",
    "    raise RuntimeError(\n",
    "        \"Missing API key. Set GOOGLE_API_KEY (preferred) or GEMINI_API_KEY in your environment. \"\n",
    "        \"Create a key in Google AI Studio, then restart this cell. See refs [1][4].\"\n",
    "    )\n",
    "\n",
    "# Optional: choose which platform to use underneath.\n",
    "# By default, the client talks to the Gemini Developer API using the key above.\n",
    "# If you want to target Vertex AI later, you can set env vars before creating the client (commented out for now) [5][6]:\n",
    "# os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = \"True\"     # tell the SDK to route via Vertex AI\n",
    "# os.environ[\"GOOGLE_CLOUD_PROJECT\"] = \"<your-gcp-project-id>\"  # needed for Vertex AI routing\n",
    "# os.environ[\"GOOGLE_CLOUD_LOCATION\"] = \"us-central1\"           # or \"europe-west1\", etc.\n",
    "\n",
    "# Create a synchronous client. Passing api_key explicitly makes the setup unambiguous and notebook-friendly [1].\n",
    "client = genai.Client(api_key=api_key)\n",
    "\n",
    "# Light connectivity smoke test: fetch a few models so we know the key works and the network path is fine [7].\n",
    "# We limit to a handful to keep output readable in a notebook.\n",
    "# models_iter = client.models.list()   returns a pager-like iterable of available base models  \n",
    "\n",
    "model_name = \"gemini-2.5-flash\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9bd027a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model replied: The client is operational.\n"
     ]
    }
   ],
   "source": [
    "# We keep the prompt trivial and deterministic so the test is stable in CI and notebooks.\n",
    "test_prompt = \"Return a single short sentence confirming the client is working.\"\n",
    "\n",
    "# You can pass a GenerateContentConfig with sampling params, but defaults are fine for this ping.\n",
    "# We explicitly set a low token cap and temperature to keep output short and predictable in a POC.\n",
    "response = client.models.generate_content(\n",
    "    model=model_name,  # the model chosen above\n",
    "    contents=test_prompt,  # plain text input for a simple first call\n",
    "    config=types.GenerateContentConfig(  # typed config keeps things explicit and discoverable [3]\n",
    "        max_output_tokens=64,  # small cap to avoid noisy output in smoke tests\n",
    "        temperature=0.2,       # slightly stochastic but near-deterministic for repeatability\n",
    "    ),\n",
    ")\n",
    "\n",
    "# The high-level text helper returns the aggregated text of the top candidate.\n",
    "print(\"Model replied:\", response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ad4ea5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ULID gives time-sortable unique IDs; great for append-only logs and human-friendly debugging.\n",
    "# We pin a lightweight lib so we don't depend on Python's stdlib UUID versions across machines.\n",
    "# We add python-slugify to build stable, human-readable candidate IDs from tool names.\n",
    "# !uv pip install ulid-py python-slugify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a8aa4bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  # filesystem ops and env access\n",
    "import json  # serialize structured outputs to disk as JSON and JSONL\n",
    "from datetime import datetime, timezone  # ISO 8601 timestamps in UTC for consistent logs\n",
    "import re  # light sanitization of domains if the model returns noisy text\n",
    "import ulid  # time-sortable unique IDs (monotonic-ish per millisecond)\n",
    "from slugify import slugify  # normalize tool names into URL-safe slugs\n",
    "import hashlib  # short deterministic hash to stabilize IDs across machines\n",
    "from typing import TypedDict, NotRequired, Literal  # simple runtime-free schema typing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2323d75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a stable, extensible record envelope. This future-proofs the append-only store.\n",
    "class IntentRecord(TypedDict):\n",
    "    id: str                                        # ULID string; unique and time-sortable\n",
    "    kind: Literal[\"capture-intent\"]                # record type tag for easy querying later\n",
    "    version: int                                   # schema version for evolvability\n",
    "    created_at: str                                # RFC3339/ISO8601 UTC timestamp\n",
    "    source: Literal[\"user-input+llm\"]              # provenance tag to aid observability\n",
    "    raw_input: str                                 # original user text, verbatim for traceability\n",
    "    data: dict                                     # arbitrarily nested payload; schema below is a guideline\n",
    "    meta: NotRequired[dict]                        # optional bag for deploy, notebook, or operator notes\n",
    "\n",
    "# Define the structured payload for the current step.\n",
    "class ToolCandidate(TypedDict):\n",
    "    tool_name: str                                 # canonical tool name, e.g., \"Salesforce\"\n",
    "    developer: NotRequired[str]                    # org or vendor, e.g., \"Salesforce, Inc.\"\n",
    "    website_domain: NotRequired[str]               # bare domain, e.g., \"salesforce.com\"\n",
    "    website_url: NotRequired[str]                  # full URL, e.g., \"https://www.salesforce.com\"\n",
    "    logo_url: NotRequired[str]                     # logo URL; see comment on Clearbit below\n",
    "    confidence: NotRequired[float]                 # model-reported confidence between 0 and 1\n",
    "    notes: NotRequired[str]                        # brief disambiguation notes for UX\n",
    "\n",
    "class ToolResolution(TypedDict):\n",
    "    # The model can propose multiple candidates; we keep them all for auditability.\n",
    "    candidates: list[ToolCandidate]                # ordered best-first by the model\n",
    "    selected_index: int                            # index into candidates that we will persist as \"current pick\"\n",
    "    disambiguation: NotRequired[str]               # short text to show the user when there’s ambiguity\n",
    "    citations: NotRequired[list[str]]              # optional URLs the model relied on (best-effort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "911ba793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read user input for the POC run\n",
    "# In your UI this would come from the single-paragraph capture screen. Here we keep it interactive for now.\n",
    "user_text = input(\"Describe the data tool you want (e.g., 'I need Salesforce data.'): \").strip()  # simple CLI input\n",
    "\n",
    "# Fail early if nothing was provided, so we don’t write empty records.\n",
    "if not user_text:\n",
    "    raise ValueError(\"Please provide a short description of the tool you want.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5eb4a2da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"tool_name\": \"Facebook\",\n",
      "      \"developer\": \"Meta Platforms, Inc.\",\n",
      "      \"website_domain\": \"facebook.com\",\n",
      "      \"website_url\": \"https://www.facebook.com\",\n",
      "      \"logo_url\": \"\",\n",
      "      \"confidence\": 1.0,\n",
      "      \"notes\": \"Social media platform\"\n",
      "    }\n",
      "  ],\n",
      "  \"selected_index\": 0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# LLM call to infer tool identity and normalize fields\n",
    "# We ask Gemini to return strict JSON that matches our schema, so later steps can be purely mechanical.\n",
    "# We do not fetch logos from the web here. Instead we heuristically set logo_url based on domain using\n",
    "# the de facto Clearbit Logo pattern: https://logo.clearbit.com/<domain> which serves favicons/logos without auth.\n",
    "# This is good enough for a local POC and can be swapped for your own asset pipeline later.\n",
    "\n",
    "# Build a compact, instruction-only prompt to minimize model verbosity and reduce parse risk.\n",
    "prompt = f\"\"\"\n",
    "You are a resolver that identifies a software/data tool from noisy user text.\n",
    "\n",
    "USER_TEXT: {user_text}\n",
    "\n",
    "Produce JSON with this structure:\n",
    "{{\n",
    "  \"candidates\": [\n",
    "    {{\n",
    "      \"tool_name\": \"<canonical tool name>\",\n",
    "      \"developer\": \"<vendor or developer, if known>\",\n",
    "      \"website_domain\": \"<registrable domain like salesforce.com, if known>\",\n",
    "      \"website_url\": \"<full homepage URL, if known>\",\n",
    "      \"logo_url\": \"\",  // leave empty; caller may set Clearbit-style logo from domain\n",
    "      \"confidence\": 0.0,  // 0 to 1\n",
    "      \"notes\": \"<one-line disambiguation or clarifying note>\"\n",
    "    }}\n",
    "  ],\n",
    "  \"selected_index\": 0,\n",
    "  \"disambiguation\": \"<one short sentence if multiple tools are plausible>\",\n",
    "  \"citations\": []  // optional URLs if you used known references\n",
    "}}\n",
    "\n",
    "Rules:\n",
    "- If multiple tools match, include the top 2-3 candidates in descending confidence and set selected_index accordingly.\n",
    "- Prefer official vendor domains, not community links.\n",
    "- If unsure, still return best-effort candidates and explain uncertainty in 'disambiguation'.\n",
    "- Return only JSON. No extra text.\n",
    "\"\"\"\n",
    "\n",
    "# Ask the model for strictly-typed JSON using the SDK’s JSON mode.\n",
    "resp = client.models.generate_content(  # high-level text generation entry point from the google-genai SDK\n",
    "    model=model_name,                   # previously selected model, e.g., \"gemini-2.5-flash\" (fast and cheap)\n",
    "    contents=prompt,                    # instruction block above\n",
    "    config=types.GenerateContentConfig( # typed config makes request explicit and helps future readers\n",
    "        response_mime_type=\"application/json\",  # request JSON so we can parse programmatically\n",
    "        response_schema=ToolResolution,         # provide a Python TypedDict to enforce shape client-side\n",
    "        temperature=0,                          # deterministic output reduces flakiness in stateful flows\n",
    "        max_output_tokens=512,                  # enough headroom for a few candidates without overrun\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Pull the parsed Python object directly. The SDK maps the JSON into native types when a schema is given.\n",
    "tool_resolution = resp.parsed  # type: ignore[assignment]  # parsed is a dict matching ToolResolution\n",
    "\n",
    "# Display raw JSON for inspection during POC runs.\n",
    "print(json.dumps(tool_resolution, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "44619e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected tool for confirmation:\n",
      "- Name: Facebook\n",
      "- Developer: Meta Platforms, Inc.\n",
      "- Domain: facebook.com\n",
      "- Logo: https://logo.clearbit.com/facebook.com\n"
     ]
    }
   ],
   "source": [
    "# post-process: sanitize domains, populate logo URL, pick selected candidate\n",
    "# Create a small helper lambda inline (not a def) to keep the \"no functions\" vibe while staying readable.\n",
    "sanitize_domain = lambda d: re.sub(r\"^https?://\", \"\", d or \"\").split(\"/\")[0].lower() if d else \"\"  # strip scheme and paths\n",
    "\n",
    "# Normalize each candidate\n",
    "normalized_candidates = []  # we’ll fill this with cleaned copies\n",
    "for cand in tool_resolution.get(\"candidates\", []):  # iterate proposed candidates in given order\n",
    "    domain = cand.get(\"website_domain\") or sanitize_domain(cand.get(\"website_url\", \"\"))  # prefer explicit domain\n",
    "    domain = sanitize_domain(domain)  # ensure bare domain shape\n",
    "    logo_url = cand.get(\"logo_url\") or (f\"https://logo.clearbit.com/{domain}\" if domain else \"\")  # Clearbit heuristic for POC\n",
    "    tool_name = cand.get(\"tool_name\", \"\").strip()  # canonical name\n",
    "    developer = (cand.get(\"developer\") or \"\").strip()  # vendor optional\n",
    "    website_url = cand.get(\"website_url\") or (f\"https://{domain}\" if domain else \"\")  # synthesize URL if domain exists\n",
    "    confidence = float(cand.get(\"confidence\", 0.0))  # numeric\n",
    "    notes = (cand.get(\"notes\") or \"\").strip()  # one-liner aid\n",
    "    \n",
    "    # New: deterministic candidateId while keeping everything else the same\n",
    "    name_slug = slugify(tool_name) or \"unknown\"  # readable component\n",
    "    hash_input = f\"{tool_name}|{domain}\".encode(\"utf-8\")  # bind identity to canonical name+domain\n",
    "    short_hash = hashlib.sha256(hash_input).hexdigest()[:12]  # compact, collision-resistant tail\n",
    "    candidate_id = f\"{name_slug}-{short_hash}\"  # final candidateId\n",
    "   \n",
    "    # Compose normalized candidate WITH candidateId added\n",
    "    normalized = {\n",
    "        \"candidateId\": candidate_id,                    # <= new stable identifier\n",
    "        \"tool_name\": tool_name,                         # trim whitespace noise\n",
    "        \"developer\": developer,                         # optional field\n",
    "        \"website_domain\": domain,                        # normalized bare domain\n",
    "        \"website_url\": website_url,                     # synthesize URL if missing\n",
    "        \"logo_url\": logo_url,                           # derived if we have a domain\n",
    "        \"confidence\": confidence,                       # ensure numeric type\n",
    "        \"notes\": notes,                                 # keep short helper text\n",
    "    }\n",
    "\n",
    "    normalized_candidates.append(normalized)  # collect normalized candidate\n",
    "\n",
    "# Fall back to a single unknown candidate if the model returned nothing for resilience.\n",
    "if not normalized_candidates:  # guardrail for empty model output\n",
    "    normalized_candidates = [{\n",
    "        \"candidateId\": \"unknown-000000000000\",  # placeholder to keep shape stable\n",
    "        \"tool_name\": \"Unknown\",\n",
    "        \"developer\": \"\",\n",
    "        \"website_domain\": \"\",\n",
    "        \"website_url\": \"\",\n",
    "        \"logo_url\": \"\",\n",
    "        \"confidence\": 0.0,\n",
    "        \"notes\": \"No candidates returned by model\",\n",
    "    }]\n",
    "\n",
    "# Clamp selected_index into range to avoid index errors if the model provided an out-of-range value.\n",
    "selected_index = int(tool_resolution.get(\"selected_index\", 0))  # parse to int\n",
    "if selected_index < 0 or selected_index >= len(normalized_candidates):  # simple bounds check\n",
    "    selected_index = 0  # default to first candidate\n",
    "\n",
    "# Compose the final structured payload that we will store.\n",
    "capture_payload = {\n",
    "    \"candidates\": normalized_candidates,                        # normalized list\n",
    "    \"selected_index\": selected_index,                           # safe index\n",
    "    \"disambiguation\": tool_resolution.get(\"disambiguation\", \"\"),# carry through for the UI\n",
    "    \"citations\": tool_resolution.get(\"citations\", []),          # optional links for traceability\n",
    "}\n",
    "\n",
    "# Pretty-print what we’ll show to the user next (name, developer, domain, logo).\n",
    "selected = normalized_candidates[selected_index]  # the current pick\n",
    "print(\"Selected tool for confirmation:\")\n",
    "print(f\"- Name: {selected['tool_name']}\")\n",
    "print(f\"- Developer: {selected['developer'] or 'Unknown'}\")\n",
    "print(f\"- Domain: {selected['website_domain'] or 'Unknown'}\")\n",
    "print(f\"- Logo: {selected['logo_url'] or 'Not available'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27c749e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote record 01K2ZFFBMHESTG7Q8CZQ54B966 to:\n",
      " - capture-intent/01K2ZFFBMHESTG7Q8CZQ54B966.json\n",
      " - capture-intent/index.jsonl (appended)\n"
     ]
    }
   ],
   "source": [
    "# persist to local state: create folder, write one-per-record JSON, append to JSONL index\n",
    "# Use an append-only JSON Lines file for an audit trail, plus per-record JSON files for random access.\n",
    "\n",
    "# Decide storage locations relative to the current notebook working directory.\n",
    "base_dir = \"capture-intent\"  # project-level folder for this stage\n",
    "os.makedirs(base_dir, exist_ok=True)  # idempotent create so reruns don’t fail\n",
    "\n",
    "# Generate a time-sortable unique ID. ULID keeps embedded timestamp which helps with chronological listings.\n",
    "record_id = str(ulid.new())  # e.g., \"01J6YP4ZQF2F7PAZ7QJX4P1C6H\"\n",
    "\n",
    "# Compose the record envelope with schema versioning for long-term evolvability.\n",
    "record: IntentRecord = {\n",
    "    \"id\": record_id,                                 # unique identifier for this capture\n",
    "    \"kind\": \"capture-intent\",                        # record type tag\n",
    "    \"version\": 1,                                    # bump when you change the shape in breaking ways\n",
    "    \"created_at\": datetime.now(timezone.utc).isoformat(),  # precise UTC timestamp with tzinfo\n",
    "    \"source\": \"user-input+llm\",                      # basic provenance for observability\n",
    "    \"raw_input\": user_text,                          # store the exact user words\n",
    "    \"data\": capture_payload,                         # normalized structured content from the model\n",
    "    \"meta\": {                                        # optional metadata bag for this notebook run\n",
    "        \"model\": model_name,                         # which base model produced this capture\n",
    "        \"sdk\": \"google-genai\",                       # which client stack we used\n",
    "        \"notebook\": \"capture_intent_poc_v1\",         # identify this workflow version\n",
    "    },\n",
    "}\n",
    "\n",
    "# Write a per-record JSON file named by ID for random access and debugging.\n",
    "per_record_path = os.path.join(base_dir, f\"{record_id}.json\")  # one file per record\n",
    "with open(per_record_path, \"w\", encoding=\"utf-8\") as f:        # open the path for writing text\n",
    "    json.dump(record, f, ensure_ascii=False, indent=2)          # pretty JSON for human inspection\n",
    "\n",
    "# Also append to a project-level JSONL index for streaming analytics or simple grepping.\n",
    "index_path = os.path.join(base_dir, \"index.jsonl\")             # append-only ledger\n",
    "with open(index_path, \"a\", encoding=\"utf-8\") as idx:           # open file in append mode\n",
    "    idx.write(json.dumps(record, ensure_ascii=False) + \"\\n\")    # write compact JSON on a single line\n",
    "\n",
    "print(f\"Wrote record {record_id} to:\")\n",
    "print(f\" - {per_record_path}\")\n",
    "print(f\" - {index_path} (appended)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8bdfea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"01K2ZFFBMHESTG7Q8CZQ54B966\",\n",
      "  \"tool_name\": \"WhatsApp\",\n",
      "  \"developer\": \"Meta Platforms\",\n",
      "  \"domain\": \"whatsapp.com\",\n",
      "  \"logo\": \"https://logo.clearbit.com/whatsapp.com\",\n",
      "  \"disambiguation\": \"\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# minimal UX echo suitable for your front end to render\n",
    "# This is intentionally tiny: your UI can lift these fields directly for the confirmation pane.\n",
    "\n",
    "display_payload = {\n",
    "    \"id\": record[\"id\"],                               # send the ID to the front end for follow-up actions\n",
    "    \"tool_name\": selected[\"tool_name\"],               # primary label\n",
    "    \"developer\": selected[\"developer\"],               # secondary label\n",
    "    \"domain\": selected[\"website_domain\"],             # used for linking and further discovery\n",
    "    \"logo\": selected[\"logo_url\"],                     # image src candidate for the UI\n",
    "    \"disambiguation\": record[\"data\"].get(\"disambiguation\", \"\"),  # optional helper text\n",
    "}\n",
    "\n",
    "print(json.dumps(display_payload, indent=2))  # easy to pick up by the front end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c618381e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "l7eiwigzd89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete - Gemini client initialized\n"
     ]
    }
   ],
   "source": [
    "# imports and environment setup\n",
    "import os  # standard library: read environment variables for keys in a secure, cross-platform way\n",
    "from google import genai  # official Google Gen AI SDK entrypoint [1]\n",
    "from google.genai import types  # typed request/response helpers, useful later for structured output [3]\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"\"\n",
    "# Read the API key from environment for safety (never hardcode secrets in notebooks or repos).\n",
    "# The SDK auto-detects GEMINI_API_KEY or GOOGLE_API_KEY; GOOGLE_API_KEY takes precedence if both exist [4].\n",
    "api_key = os.environ.get(\"GOOGLE_API_KEY\") or os.environ.get(\"GEMINI_API_KEY\")\n",
    "\n",
    "# Fail fast with a clear message if no key is present, and point the user at the official place to create one.\n",
    "if not api_key:\n",
    "    raise RuntimeError(\n",
    "        \"Missing API key. Set GOOGLE_API_KEY (preferred) or GEMINI_API_KEY in your environment. \"\n",
    "        \"Create a key in Google AI Studio, then restart this cell. See refs [1][4].\"\n",
    "    )\n",
    "\n",
    "# Optional: choose which platform to use underneath.\n",
    "# By default, the client talks to the Gemini Developer API using the key above.\n",
    "# If you want to target Vertex AI later, you can set env vars before creating the client (commented out for now) [5][6]:\n",
    "# os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = \"True\"     # tell the SDK to route via Vertex AI\n",
    "# os.environ[\"GOOGLE_CLOUD_PROJECT\"] = \"<your-gcp-project-id>\"  # needed for Vertex AI routing\n",
    "# os.environ[\"GOOGLE_CLOUD_LOCATION\"] = \"us-central1\"           # or \"europe-west1\", etc.\n",
    "\n",
    "# Create a synchronous client. Passing api_key explicitly makes the setup unambiguous and notebook-friendly [1].\n",
    "client = genai.Client(api_key=api_key)\n",
    "\n",
    "# Light connectivity smoke test: fetch a few models so we know the key works and the network path is fine [7].\n",
    "# We limit to a handful to keep output readable in a notebook.\n",
    "# models_iter = client.models.list()   returns a pager-like iterable of available base models  \n",
    "\n",
    "model_name = \"gemini-2.5-flash\"\n",
    "print(\"Setup complete - Gemini client initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3nndm26x03l",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model replied: Client is operational.\n"
     ]
    }
   ],
   "source": [
    "# We keep the prompt trivial and deterministic so the test is stable in CI and notebooks.\n",
    "test_prompt = \"Return a single short sentence confirming the client is working.\"\n",
    "\n",
    "# You can pass a GenerateContentConfig with sampling params, but defaults are fine for this ping.\n",
    "# We explicitly set a low token cap and temperature to keep output short and predictable in a POC.\n",
    "response = client.models.generate_content(\n",
    "    model=model_name,  # the model chosen above\n",
    "    contents=test_prompt,  # plain text input for a simple first call\n",
    "    config=types.GenerateContentConfig(  # typed config keeps things explicit and discoverable [3]\n",
    "        max_output_tokens=64,  # small cap to avoid noisy output in smoke tests\n",
    "        temperature=0.2,       # slightly stochastic but near-deterministic for repeatability\n",
    "    ),\n",
    ")\n",
    "\n",
    "# The high-level text helper returns the aggregated text of the top candidate.\n",
    "print(\"Model replied:\", response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6yqnvjw3ue",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependencies imported successfully\n"
     ]
    }
   ],
   "source": [
    "import os  # filesystem ops and env access\n",
    "import json  # serialize structured outputs to disk as JSON and JSONL\n",
    "import hashlib  # for generating stable candidate IDs\n",
    "from datetime import datetime, timezone  # ISO 8601 timestamps in UTC for consistent logs\n",
    "import re  # light sanitization of domains if the model returns noisy text\n",
    "import ulid  # time-sortable unique IDs (monotonic-ish per millisecond)\n",
    "from slugify import slugify  # normalize tool names into URL-safe slugs\n",
    "from typing import TypedDict, NotRequired, Literal  # simple runtime-free schema typing\n",
    "\n",
    "print(\"Dependencies imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "at9ps1dn33n",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TypedDict schemas defined\n"
     ]
    }
   ],
   "source": [
    "# Define a stable, extensible record envelope. This future-proofs the append-only store.\n",
    "class IntentRecord(TypedDict):\n",
    "    id: str                                        # ULID string; unique and time-sortable\n",
    "    kind: Literal[\"capture-intent\"]                # record type tag for easy querying later\n",
    "    version: int                                   # schema version for evolvability\n",
    "    created_at: str                                # RFC3339/ISO8601 UTC timestamp\n",
    "    source: Literal[\"user-input+llm\"]              # provenance tag to aid observability\n",
    "    raw_input: str                                 # original user text, verbatim for traceability\n",
    "    data: dict                                     # arbitrarily nested payload; schema below is a guideline\n",
    "    meta: NotRequired[dict]                        # optional bag for deploy, notebook, or operator notes\n",
    "\n",
    "# Define the structured payload for the current step.\n",
    "class ToolCandidate(TypedDict):\n",
    "    tool_name: str                                 # canonical tool name, e.g., \"Salesforce\"\n",
    "    developer: NotRequired[str]                    # org or vendor, e.g., \"Salesforce, Inc.\"\n",
    "    website_domain: NotRequired[str]               # bare domain, e.g., \"salesforce.com\"\n",
    "    website_url: NotRequired[str]                  # full URL, e.g., \"https://www.salesforce.com\"\n",
    "    logo_url: NotRequired[str]                     # logo URL; see comment on Clearbit below\n",
    "    confidence: NotRequired[float]                 # model-reported confidence between 0 and 1\n",
    "    notes: NotRequired[str]                        # brief disambiguation notes for UX\n",
    "\n",
    "class ToolResolution(TypedDict):\n",
    "    # The model can propose multiple candidates; we keep them all for auditability.\n",
    "    candidates: list[ToolCandidate]                # ordered best-first by the model\n",
    "    selected_index: int                            # index into candidates that we will persist as \"current pick\"\n",
    "    disambiguation: NotRequired[str]               # short text to show the user when there's ambiguity\n",
    "    citations: NotRequired[list[str]]              # optional URLs the model relied on (best-effort)\n",
    "\n",
    "print(\"TypedDict schemas defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3qpbvna2y9o",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User input captured: 'hibob'\n"
     ]
    }
   ],
   "source": [
    "# read user input for the POC run\n",
    "# In your UI this would come from the single-paragraph capture screen. Here we simulate with \"hibob\"\n",
    "user_text = input(\"Describe the data tool you want (e.g., 'I need Salesforce customer data'): \").strip()  # interactive entry point\n",
    "\n",
    "# Fail early if nothing was provided, so we don't write empty records.\n",
    "if not user_text:\n",
    "    raise ValueError(\"Please provide a short description of the tool you want.\")\n",
    "    \n",
    "print(f\"User input captured: '{user_text}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "o3e1v0lhnj",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Resolution Result:\n",
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"tool_name\": \"HiBob\",\n",
      "      \"developer\": \"HiBob\",\n",
      "      \"website_domain\": \"hibob.com\",\n",
      "      \"website_url\": \"https://www.hibob.com/\",\n",
      "      \"logo_url\": \"\",\n",
      "      \"confidence\": 1.0,\n",
      "      \"notes\": \"HR and people management platform\"\n",
      "    }\n",
      "  ],\n",
      "  \"selected_index\": 0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# LLM call to infer tool identity and normalize fields\n",
    "# We ask Gemini to return strict JSON that matches our schema, so later steps can be purely mechanical.\n",
    "# We do not fetch logos from the web here. Instead we heuristically set logo_url based on domain using\n",
    "# the de facto Clearbit Logo pattern: https://logo.clearbit.com/<domain> which serves favicons/logos without auth.\n",
    "# This is good enough for a local POC and can be swapped for your own asset pipeline later.\n",
    "\n",
    "# Build a compact, instruction-only prompt to minimize model verbosity and reduce parse risk.\n",
    "prompt = f\"\"\"\n",
    "You are a resolver that identifies a software/data tool from noisy user text.\n",
    "\n",
    "USER_TEXT: {user_text}\n",
    "\n",
    "Produce JSON with this structure:\n",
    "{{\n",
    "  \"candidates\": [\n",
    "    {{\n",
    "      \"tool_name\": \"<canonical tool name>\",\n",
    "      \"developer\": \"<vendor or developer, if known>\",\n",
    "      \"website_domain\": \"<registrable domain like salesforce.com, if known>\",\n",
    "      \"website_url\": \"<full homepage URL, if known>\",\n",
    "      \"logo_url\": \"\",  // leave empty; caller may set Clearbit-style logo from domain\n",
    "      \"confidence\": 0.0,  // 0 to 1\n",
    "      \"notes\": \"<one-line disambiguation or clarifying note>\"\n",
    "    }}\n",
    "  ],\n",
    "  \"selected_index\": 0,\n",
    "  \"disambiguation\": \"<one short sentence if multiple tools are plausible>\",\n",
    "  \"citations\": []  // optional URLs if you used known references\n",
    "}}\n",
    "\n",
    "Rules:\n",
    "- If multiple tools match, include the top 2-3 candidates in descending confidence and set selected_index accordingly.\n",
    "- Prefer official vendor domains, not community links.\n",
    "- If unsure, still return best-effort candidates and explain uncertainty in 'disambiguation'.\n",
    "- Return only JSON. No extra text.\n",
    "\"\"\"\n",
    "\n",
    "# Ask the model for strictly-typed JSON using the SDK's JSON mode.\n",
    "resp = client.models.generate_content(  # high-level text generation entry point from the google-genai SDK\n",
    "    model=model_name,                   # previously selected model, e.g., \"gemini-2.5-flash\" (fast and cheap)\n",
    "    contents=prompt,                    # instruction block above\n",
    "    config=types.GenerateContentConfig( # typed config makes request explicit and helps future readers\n",
    "        response_mime_type=\"application/json\",  # request JSON so we can parse programmatically\n",
    "        response_schema=ToolResolution,         # provide a Python TypedDict to enforce shape client-side\n",
    "        temperature=0,                          # deterministic output reduces flakiness in stateful flows\n",
    "        max_output_tokens=512,                  # enough headroom for a few candidates without overrun\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Pull the parsed Python object directly. The SDK maps the JSON into native types when a schema is given.\n",
    "tool_resolution = resp.parsed  # type: ignore[assignment]  # parsed is a dict matching ToolResolution\n",
    "\n",
    "# Display raw JSON for inspection during POC runs.\n",
    "print(\"LLM Resolution Result:\")\n",
    "print(json.dumps(tool_resolution, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "p4mk8ukumvq",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected tool for confirmation:\n",
      "- Name: HiBob\n",
      "- Developer: HiBob\n",
      "- Domain: hibob.com\n",
      "- Logo: https://logo.clearbit.com/hibob.com\n",
      "- Candidate ID: hibob-8f11b0239b49\n",
      "- Confidence: 1.0\n",
      "- Notes: HR and people management platform\n"
     ]
    }
   ],
   "source": [
    "# post-process: sanitize domains, populate logo URL, pick selected candidate\n",
    "# Create a small helper lambda inline (not a def) to keep the \"no functions\" vibe while staying readable.\n",
    "sanitize_domain = lambda d: re.sub(r\"^https?://\", \"\", d or \"\").split(\"/\")[0].lower() if d else \"\"  # strip scheme and paths\n",
    "\n",
    "# Normalize each candidate\n",
    "normalized_candidates = []  # we'll fill this with cleaned copies\n",
    "for cand in tool_resolution.get(\"candidates\", []):  # iterate proposed candidates in given order\n",
    "    domain = cand.get(\"website_domain\") or sanitize_domain(cand.get(\"website_url\", \"\"))  # prefer explicit domain\n",
    "    domain = sanitize_domain(domain)  # ensure bare domain shape\n",
    "    logo_url = cand.get(\"logo_url\") or (f\"https://logo.clearbit.com/{domain}\" if domain else \"\")  # Clearbit heuristic for POC\n",
    "    tool_name = cand.get(\"tool_name\", \"\").strip()  # canonical name\n",
    "    developer = (cand.get(\"developer\") or \"\").strip()  # vendor optional\n",
    "    website_url = cand.get(\"website_url\") or (f\"https://{domain}\" if domain else \"\")  # synthesize URL if domain exists\n",
    "    confidence = float(cand.get(\"confidence\", 0.0))  # numeric\n",
    "    notes = (cand.get(\"notes\") or \"\").strip()  # one-liner aid\n",
    "    \n",
    "    # New: deterministic candidateId while keeping everything else the same\n",
    "    name_slug = slugify(tool_name) or \"unknown\"  # readable component\n",
    "    hash_input = f\"{tool_name}|{domain}\".encode(\"utf-8\")  # bind identity to canonical name+domain\n",
    "    short_hash = hashlib.sha256(hash_input).hexdigest()[:12]  # compact, collision-resistant tail\n",
    "    candidate_id = f\"{name_slug}-{short_hash}\"  # final candidateId\n",
    "   \n",
    "    # Compose normalized candidate WITH candidateId added\n",
    "    normalized = {\n",
    "        \"candidateId\": candidate_id,                    # <= new stable identifier\n",
    "        \"tool_name\": tool_name,                         # trim whitespace noise\n",
    "        \"developer\": developer,                         # optional field\n",
    "        \"website_domain\": domain,                        # normalized bare domain\n",
    "        \"website_url\": website_url,                     # synthesize URL if missing\n",
    "        \"logo_url\": logo_url,                           # derived if we have a domain\n",
    "        \"confidence\": confidence,                       # ensure numeric type\n",
    "        \"notes\": notes,                                 # keep short helper text\n",
    "    }\n",
    "\n",
    "    normalized_candidates.append(normalized)  # collect normalized candidate\n",
    "\n",
    "# Fall back to a single unknown candidate if the model returned nothing for resilience.\n",
    "if not normalized_candidates:  # guardrail for empty model output\n",
    "    normalized_candidates = [{\n",
    "        \"candidateId\": \"unknown-000000000000\",  # placeholder to keep shape stable\n",
    "        \"tool_name\": \"Unknown\",\n",
    "        \"developer\": \"\",\n",
    "        \"website_domain\": \"\",\n",
    "        \"website_url\": \"\",\n",
    "        \"logo_url\": \"\",\n",
    "        \"confidence\": 0.0,\n",
    "        \"notes\": \"No candidates returned by model\",\n",
    "    }]\n",
    "\n",
    "# Clamp selected_index into range to avoid index errors if the model provided an out-of-range value.\n",
    "selected_index = int(tool_resolution.get(\"selected_index\", 0))  # parse to int\n",
    "if selected_index < 0 or selected_index >= len(normalized_candidates):  # simple bounds check\n",
    "    selected_index = 0  # default to first candidate\n",
    "\n",
    "# Compose the final structured payload that we will store.\n",
    "capture_payload = {\n",
    "    \"candidates\": normalized_candidates,                        # normalized list\n",
    "    \"selected_index\": selected_index,                           # safe index\n",
    "    \"disambiguation\": tool_resolution.get(\"disambiguation\", \"\"),# carry through for the UI\n",
    "    \"citations\": tool_resolution.get(\"citations\", []),          # optional links for traceability\n",
    "}\n",
    "\n",
    "# Pretty-print what we'll show to the user next (name, developer, domain, logo).\n",
    "selected = normalized_candidates[selected_index]  # the current pick\n",
    "print(\"Selected tool for confirmation:\")\n",
    "print(f\"- Name: {selected['tool_name']}\")\n",
    "print(f\"- Developer: {selected['developer'] or 'Unknown'}\")\n",
    "print(f\"- Domain: {selected['website_domain'] or 'Unknown'}\")\n",
    "print(f\"- Logo: {selected['logo_url'] or 'Not available'}\")\n",
    "print(f\"- Candidate ID: {selected['candidateId']}\")\n",
    "print(f\"- Confidence: {selected['confidence']}\")\n",
    "print(f\"- Notes: {selected['notes']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "iilvjhwl5hn",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote record 01K317V3K6J1TZEBK32SZZKCZK to:\n",
      " - capture-intent/01K317V3K6J1TZEBK32SZZKCZK.json\n",
      " - capture-intent/index.jsonl (appended)\n"
     ]
    }
   ],
   "source": [
    "# persist to local state: create folder, write one-per-record JSON, append to JSONL index\n",
    "# Use an append-only JSON Lines file for an audit trail, plus per-record JSON files for random access.\n",
    "\n",
    "# Decide storage locations relative to the current notebook working directory.\n",
    "base_dir = \"capture-intent\"  # project-level folder for this stage\n",
    "os.makedirs(base_dir, exist_ok=True)  # idempotent create so reruns don't fail\n",
    "\n",
    "# Generate a time-sortable unique ID. ULID keeps embedded timestamp which helps with chronological listings.\n",
    "record_id = str(ulid.new())  # e.g., \"01J6YP4ZQF2F7PAZ7QJX4P1C6H\"\n",
    "\n",
    "# Compose the record envelope with schema versioning for long-term evolvability.\n",
    "record: IntentRecord = {\n",
    "    \"id\": record_id,                                 # unique identifier for this capture\n",
    "    \"kind\": \"capture-intent\",                        # record type tag\n",
    "    \"version\": 1,                                    # bump when you change the shape in breaking ways\n",
    "    \"created_at\": datetime.now(timezone.utc).isoformat(),  # precise UTC timestamp with tzinfo\n",
    "    \"source\": \"user-input+llm\",                      # basic provenance for observability\n",
    "    \"raw_input\": user_text,                          # store the exact user words\n",
    "    \"data\": capture_payload,                         # normalized structured content from the model\n",
    "    \"meta\": {                                        # optional metadata bag for this notebook run\n",
    "        \"model\": model_name,                         # which base model produced this capture\n",
    "        \"sdk\": \"google-genai\",                       # which client stack we used\n",
    "        \"notebook\": \"capture_intent_poc_v2\",         # identify this workflow version\n",
    "    },\n",
    "}\n",
    "\n",
    "# Write a per-record JSON file named by ID for random access and debugging.\n",
    "per_record_path = os.path.join(base_dir, f\"{record_id}.json\")  # one file per record\n",
    "with open(per_record_path, \"w\", encoding=\"utf-8\") as f:        # open the path for writing text\n",
    "    json.dump(record, f, ensure_ascii=False, indent=2)          # pretty JSON for human inspection\n",
    "\n",
    "# Also append to a project-level JSONL index for streaming analytics or simple grepping.\n",
    "index_path = os.path.join(base_dir, \"index.jsonl\")             # append-only ledger\n",
    "with open(index_path, \"a\", encoding=\"utf-8\") as idx:           # open file in append mode\n",
    "    idx.write(json.dumps(record, ensure_ascii=False) + \"\\n\")    # write compact JSON on a single line\n",
    "\n",
    "print(f\"Wrote record {record_id} to:\")\n",
    "print(f\" - {per_record_path}\")\n",
    "print(f\" - {index_path} (appended)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ki7t9ftcyrr",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final display payload for UI:\n",
      "{\n",
      "  \"id\": \"01K317V3K6J1TZEBK32SZZKCZK\",\n",
      "  \"tool_name\": \"HiBob\",\n",
      "  \"developer\": \"HiBob\",\n",
      "  \"domain\": \"hibob.com\",\n",
      "  \"logo\": \"https://logo.clearbit.com/hibob.com\",\n",
      "  \"disambiguation\": \"\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# minimal UX echo suitable for your front end to render\n",
    "# This is intentionally tiny: your UI can lift these fields directly for the confirmation pane.\n",
    "\n",
    "display_payload = {\n",
    "    \"id\": record[\"id\"],                               # send the ID to the front end for follow-up actions\n",
    "    \"tool_name\": selected[\"tool_name\"],               # primary label\n",
    "    \"developer\": selected[\"developer\"],               # secondary label\n",
    "    \"domain\": selected[\"website_domain\"],             # used for linking and further discovery\n",
    "    \"logo\": selected[\"logo_url\"],                     # image src candidate for the UI\n",
    "    \"disambiguation\": record[\"data\"].get(\"disambiguation\", \"\"),  # optional helper text\n",
    "}\n",
    "\n",
    "print(\"Final display payload for UI:\")\n",
    "print(json.dumps(display_payload, indent=2))  # easy to pick up by the front end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "platform",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
